{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCG-Unet Note\n",
    "\n",
    "Please ensure that you have use `poetry` or `pip` to install the dependencies.\n",
    "\n",
    "> run `poetry install` or `pip -r requirements.txt` to install them.\n",
    "\n",
    "> If you are on Colab, the dependencies are already satisfied.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset\n",
    "\n",
    "We need to download the dataset if it's not exist on your local machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset if not present\n",
    "import hashlib\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "DATASET_PATH = os.path.normpath(\"./data/EyeClose1_noscan.mat\")\n",
    "DATASET_URL = \"https://bcgunet-data.csie.cool/EyeClose1_noscan.mat\"\n",
    "\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    res = requests.get(DATASET_URL, stream=True)\n",
    "    with tqdm.wrapattr(\n",
    "        open(DATASET_PATH, \"wb\"),\n",
    "        \"write\",\n",
    "        miniters=1,\n",
    "        desc=\"Downloading dataset\",\n",
    "        total=int(res.headers.get(\"content-length\", default=\"0\")),\n",
    "    ) as file:\n",
    "        for chunk in res.iter_content(chunk_size=4096):\n",
    "            file.write(chunk)\n",
    "        file.close()\n",
    "    SHA = \"d36a16ad45302971843a6d413eb833f407fd4146c3e32dfe23bdd8a17ccba2cb\"\n",
    "    assert (\n",
    "        SHA == hashlib.sha256(open(DATASET_PATH, \"rb\").read()).hexdigest()\n",
    "    ), \"Dataset is corrupted!\"\n",
    "    print(\"Dataset downloaded!\")\n",
    "else:\n",
    "    print(\"Dataset already exists!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "There is a ECG channel and 31 EEG (BCE, BCG Corrupted EEG) channels in the dataset.\n",
    "\n",
    "Also, a 31-channel OBS processed EEG is provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise FileNotFoundError(DATASET_PATH)\n",
    "\n",
    "f = h5py.File(DATASET_PATH, \"r\")\n",
    "ECG = np.array(f[\"ECG\"]).flatten()\n",
    "# BCG Corrupted EEG\n",
    "BCE = np.array(f[\"EEG_before_bcg\"]).T\n",
    "EEG_OBS = np.array(f[\"EEG\"]).T\n",
    "print(\"shape of ECG:     \", ECG.shape)\n",
    "print(\"shape of EEG:     \", BCE.shape)\n",
    "print(\"shape of EEG_OBS: \", EEG_OBS.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Let's use the data between 4 and 10 second of those signals. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLE_FREQ = 5000\n",
    "START_SEC = 4\n",
    "END_SEC = 14\n",
    "\n",
    "ECG_all = ECG\n",
    "# ECG = ECG[SAMPLE_FREQ * START_SEC : SAMPLE_FREQ * END_SEC]\n",
    "BCE_all = BCE\n",
    "# BCE = BCE.T[SAMPLE_FREQ * START_SEC : SAMPLE_FREQ * END_SEC].T\n",
    "EEG_OBS_all = EEG_OBS\n",
    "# EEG_OBS = EEG_OBS.T[SAMPLE_FREQ * START_SEC : SAMPLE_FREQ * END_SEC].T\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(ECG)\n",
    "plt.title(\"ECG\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(BCE.T)\n",
    "plt.title(\"BCE\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(EEG_OBS.T)\n",
    "plt.title(\"EEG_OBS\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Baseline of each EEG Channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfilt\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(\n",
    "    data: np.ndarray, fs: float, lowcut: float, highcut: float, order=5\n",
    "):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq  # 1/fs [why?]\n",
    "    high = highcut / nyq  # 0.8\n",
    "    sos = butter(order, [low, high], analog=False, btype=\"band\", output=\"sos\")\n",
    "    y = sosfilt(sos, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "BCE_filtered = BCE * 0\n",
    "BCE_all_filtered = BCE_all * 0\n",
    "for ii in range(31):\n",
    "    BCE_filtered[ii, ...] = butter_bandpass_filter(\n",
    "        BCE[ii, :], SAMPLE_FREQ, 0.5, SAMPLE_FREQ * 0.4\n",
    "    )\n",
    "    BCE_all_filtered[ii, ...] = butter_bandpass_filter(\n",
    "        BCE_all[ii, :], SAMPLE_FREQ, 0.5, SAMPLE_FREQ * 0.4\n",
    "    )\n",
    "\n",
    "BCE_baseline = BCE - BCE_filtered\n",
    "BCE_all_baseline = BCE_all - BCE_all_filtered\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(BCE_filtered.T)\n",
    "plt.title(\"BCE_filtered\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(BCE_baseline.T)\n",
    "plt.title(\"BCE_baseline\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store losses between different methods\n",
    "loss_data = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the BCG-Unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    \"\"\"convolution => [BN] => ReLU\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_groups=4):\n",
    "        super().__init__()\n",
    "        # self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv = nn.utils.weight_norm(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.group_norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            Conv(in_channels, mid_channels), Conv(mid_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool1d(2), DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"linear\", align_corners=True)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet1d(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, nfilter=24, nlayer=4):\n",
    "        super(UNet1d, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.nfilter = nfilter\n",
    "        self.nlayer = nlayer\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, nfilter)\n",
    "\n",
    "        for i in range(nlayer - 1):\n",
    "            setattr(self, f\"down{i+1}\", Down(nfilter * 2**i, nfilter * 2 ** (i + 1)))\n",
    "        setattr(\n",
    "            self,\n",
    "            f\"down{nlayer}\",\n",
    "            Down(nfilter * 2 ** (nlayer - 1), nfilter * 2 ** (nlayer - 1)),\n",
    "        )\n",
    "\n",
    "        for i in range(nlayer):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"up{i+1}\",\n",
    "                Up(\n",
    "                    nfilter * 2 ** (nlayer - i),\n",
    "                    nfilter * 2 ** (nlayer - i - 2 if nlayer - i - 2 >= 0 else 0),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.outc = OutConv(nfilter, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inc(x)\n",
    "\n",
    "        downs = []\n",
    "        for i in range(self.nlayer):\n",
    "            downs.append(x)\n",
    "            x = getattr(self, f\"down{i+1}\")(x)\n",
    "\n",
    "        for i in range(self.nlayer):\n",
    "            x = getattr(self, f\"up{i+1}\")(x, downs.pop())\n",
    "\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "EEG_CHANNEL = 31\n",
    "LEARNING_RATE = 1e-3\n",
    "ITERATION_STEPS = 5000\n",
    "WINDOW = 2 * SAMPLE_FREQ\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NET = UNet1d(n_channels=1, n_classes=EEG_CHANNEL, nfilter=8).to(device)\n",
    "\n",
    "print(NET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Train the BCG-Unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(nfilter = 8, nlayer = 5):\n",
    "    torch.cuda.empty_cache()\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    NET = UNet1d(n_channels=1, n_classes=EEG_CHANNEL, nfilter=nfilter, nlayer=nlayer).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(NET.parameters())\n",
    "    optimizer.zero_grad()\n",
    "    maxlen = ECG.size\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=LEARNING_RATE, total_steps=ITERATION_STEPS\n",
    "    )\n",
    "\n",
    "    picked_idx = (np.random.random_sample(ITERATION_STEPS) * (maxlen - WINDOW)).astype(int)\n",
    "\n",
    "    iter_loss = []\n",
    "    loss_list = []\n",
    "\n",
    "    pbar = tqdm(picked_idx)\n",
    "    count = 0\n",
    "    for idx in pbar:\n",
    "        count += 1\n",
    "        ECG_batch = ECG[idx : idx + WINDOW]\n",
    "        BCE_batch = BCE_filtered[:, idx : idx + WINDOW]\n",
    "        ECG_data = torch.from_numpy(ECG_batch[None, ...][None, ...]).float().to(device)\n",
    "        BCE_data = torch.from_numpy(BCE_batch[None, ...]).float().to(device)\n",
    "\n",
    "        logits = NET(ECG_data)\n",
    "        loss = nn.functional.mse_loss(logits, BCE_data)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        loss.backward()  # Accumulate the gradients\n",
    "        optimizer.step()  # Update network weights according to the optimizer\n",
    "        optimizer.zero_grad()  # Reset the gradients\n",
    "        scheduler.step()\n",
    "\n",
    "        if count % 50 == 0:\n",
    "            pbar.set_description(\n",
    "                f\"Loss {np.mean(loss_list):.3f}, lr: {optimizer.param_groups[0]['lr']:.5f}\"\n",
    "            )\n",
    "            iter_loss.append(np.mean(loss_list))\n",
    "            loss_list = []\n",
    "\n",
    "    loss_data.append((iter_loss, nfilter, nlayer))\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(iter_loss)\n",
    "    plt.title(f\"Loss ({nfilter} filters, {nlayer} layers)\")\n",
    "    plt.show()\n",
    "\n",
    "run(nfilter=8, nlayer=4)\n",
    "\n",
    "plt.figure(figsize=(40, 10))\n",
    "for loss in loss_data:\n",
    "    plt.plot(loss[0], label=f\"{loss[1]} filters, {loss[2]} layers\")\n",
    "plt.title(f\"Losses of {len(loss_data)} runs\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Make a Prediction with BCG-Unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG_data = torch.from_numpy(ECG_all[None, ...][None, ...]).float().to(device)\n",
    "BCE_data = torch.from_numpy(BCE_all_filtered[None, ...]).float().to(device)\n",
    "\n",
    "print(\"ECG Channel: \", ECG_data.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = NET(ECG_data)\n",
    "    BCG_pred = logits.cpu().detach().numpy()[0, ...]\n",
    "    EEG_pred = BCE_all - BCG_pred + BCE_all_baseline\n",
    "    pred_loss = nn.functional.mse_loss(logits, BCE_data).item()\n",
    "\n",
    "\n",
    "print(\"BCG Channel: \", BCG_pred.shape[0])\n",
    "\n",
    "print(\"prediction loss: \", pred_loss)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(BCG_pred.T)\n",
    "plt.title(\"BCG_pred (channel:\" + str(BCG_pred.shape[0]) + \")\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(EEG_pred.T)\n",
    "plt.title(\"EEG_pred\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(EEG_OBS_all.T)\n",
    "plt.title(\"EEG_OBS\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee97d551dedb1935fab406f1c46d518c2283b7de15ea41741866200bf693e0e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
